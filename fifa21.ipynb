{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f99752-fe87-4a26-902f-d226a493e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75555cc6-6bec-4922-a718-6b161aba392e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/players_21.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m players_data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/players_21.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Read the players data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(players_data_path)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Display the data table for preview\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/players_21.csv'"
     ]
    }
   ],
   "source": [
    "# players_21 data files\n",
    "players_data_path = \"data/players_21.csv\"\n",
    "\n",
    "# Read the players data\n",
    "df = pd.read_csv(players_data_path)\n",
    "\n",
    "# Display the data table for preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c08a8-aaab-4e95-9d2a-917af0311981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing \n",
    "#df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94bb78-451a-438a-b038-7ae7cd4ed774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check height and weight columns if they have the appropriate data type (should be in integers int64)\n",
    "df[['height_cm', 'weight_kg']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e15f81-dca5-49ee-a192-5ba69aeadd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatype of 'joined' column\n",
    "df['joined'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a97064-8381-46c3-8ff2-bb3fbf5e91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'joined' column into datatime, \n",
    "df['joined'] = pd.to_datetime(df['joined'], errors='coerce')\n",
    "\n",
    "# then extract the year, month, and day into 3 separate cols\n",
    "df['joined_year'] = df['joined'].dt.year\n",
    "df['joined_month'] = df['joined'].dt.month\n",
    "df['joined_day'] = df['joined'].dt.day\n",
    "\n",
    "# Display the results\n",
    "df[['joined', 'joined_year', 'joined_month', 'joined_day']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7eb087-2b7d-48ed-bea9-306ef03920df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatype of 'value, wage, release clause' cols\n",
    "df[['value_eur', 'wage_eur', 'release_clause_eur']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d568d2b-4c21-4c6e-9bf2-08726aa8a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert float to int\n",
    "df['release_clause_eur'] = df['release_clause_eur'].fillna(0).astype(int)\n",
    "\n",
    "# Verify the change\n",
    "df[['release_clause_eur']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5dfcc3-4e8f-4327-8128-bdad76aabd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results of the 3 cols\n",
    "df[['value_eur', 'wage_eur', 'release_clause_eur']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee8ff4c-e7e4-44d8-92b2-eed340352cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contract_valid_until'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19689cfe-7e69-44f9-a702-f681c98ddb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to int\n",
    "df['contract_valid_until'] = df['contract_valid_until'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3672230-a49d-462d-a12b-ce3fdf189925",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check if there's missing values in the dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m missing_values \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      3\u001b[0m missing_values\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Check if there's missing values in the dataset\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea078a5e-1375-421c-9fe5-796ac600baba",
   "metadata": {},
   "source": [
    "## Player Performance vs Wage\n",
    "- Analyze if higher wages correlate with better player performance ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc3d61-cadd-4d32-b7f9-2f2773c9f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns for analysis (wage and overall rating)\n",
    "df_performance = df[['wage_eur', 'overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b277e8-2fb7-4680-89ca-6079ea1edccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the players with a wage of zero from thsi analysis, as they could be outliers or represent missing data\n",
    "# which could distort the results\n",
    "df_performance = df_performance[df_performance['wage_eur'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516863f-d19d-4ebf-9639-2e3d1f89c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Check for any missing data and clean if necessary\n",
    "df_performance = df_performance.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5e1a3-0cae-4a41-ab39-cb67cb962731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define wage bins\n",
    "wage_bins = [0, 10000, 20000, 50000, 100000, 200000, 500000, 1000000]  # Define wage ranges\n",
    "wage_labels = ['0-10K', '10K-20K', '20K-50K', '50K-100K', '100K-200K', '200K-500K', '500K-1M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c18db-3f85-4883-b2bd-5f3957d5228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin the wages\n",
    "df_performance['wage_bin'] = pd.cut(df_performance['wage_eur'], bins=wage_bins, labels=wage_labels)\n",
    "df_performance = df_performance.sort_values(by='wage_bin')\n",
    "df_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a221bbb-4618-4b53-a7b0-e81f690c7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot to visualize the relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_performance['wage_eur'],df_performance['overall'])\n",
    "plt.title('Player Wages vs Overall Ratings')\n",
    "plt.xlabel('Wage (EUR)')\n",
    "plt.ylabel('Overall Performance Rating')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d86a257-c3cf-494d-9115-96219f5398cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation coefficient\n",
    "correlation = df_performance['wage_eur'].corr(df_performance['overall'])\n",
    "print(f\"Correlation between wage and overall performance: {correlation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11f977e-8e01-4ae0-82e8-ebda8d6872c3",
   "metadata": {},
   "source": [
    "- A correlation coefficient of 0.5809 indicates a moderate positive relationship between player wages and overall performance ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f9fc0b-9cf7-4edf-8647-b681373879a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a linear regression model\n",
    "model = st.linregress(df_performance['wage_eur'],df_performance['overall'])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a407f896-f620-4c1e-81fd-07ebe3ed6cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter plot with regression\n",
    "y_values = df_performance['wage_eur']*model[0]+model[1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_performance['wage_eur'],df_performance['overall'])\n",
    "plt.plot(df_performance['wage_eur'], y_values, 'r-', label=\"Regression line\")\n",
    "plt.title('Player Wages vs Overall Ratings')\n",
    "plt.xlabel('Wage (EUR)')\n",
    "plt.ylabel('Overall Performance Rating')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377bd71e-9235-442f-add0-9d1c9fcb1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Group by wage_bin and calculate summary statistics for overall performance\n",
    "summary_stats_binned = df_performance.groupby('wage_bin')['overall'].agg(['mean', 'median', 'var', 'std', 'sem'])\n",
    "\n",
    "# Display the binned summary statistics\n",
    "summary_stats_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f43f33-2b84-4b5c-8f5f-a1b4d246104c",
   "metadata": {},
   "source": [
    "- Comparing the mean overall ratings across the wage bins. The higher wage bins have significantly higher mean overall ratings, the players with higher wages generally perform better\n",
    "- The median across wage bins follows the same pattern as the mean (increasing with wage), it supports the observation that hgiher wages are associated with better players.\n",
    "- Variance for the lower wage bin 0-10k is high, this means there's a large spread in the overall ratings. It has mixed performance levels, with both high and low performers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8a151-8d0f-4728-a624-643d9d052311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bar graph\n",
    "mean_performance_by_bin = df_performance.groupby('wage_bin')['overall'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "mean_performance_by_bin.plot(kind='bar')\n",
    "plt.title('Mean Overall Performance by Wage Bin')\n",
    "plt.xlabel('Wage Bin (EUR)')\n",
    "plt.ylabel('Mean Overall Performance')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe823ce-e4c8-47e5-bfa5-87ed2733a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot for Wages\n",
    "box_data = [df_performance[df_performance['wage_bin'] == label]['overall'] for label in wage_labels]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(box_data, labels=wage_labels, patch_artist=True, boxprops=dict(facecolor='skyblue', color='blue'),\n",
    "            medianprops=dict(color='red'), whiskerprops=dict(color='blue'), capprops=dict(color='blue'))\n",
    "\n",
    "plt.title('Overall Performance by Wage Bin')\n",
    "plt.xlabel('Wage Bin (EUR)')\n",
    "plt.ylabel('Overall Performance Rating')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d7c932-dec5-4ddf-a15c-1807867184fe",
   "metadata": {},
   "source": [
    "## Position Analysis\n",
    "- Analyze which positions (forwards, midfielders, etc) have the highest overall ratings or wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e7683-bdee-40c2-abf4-2c06dce8f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame of the analysis of performance\n",
    "\n",
    "#Calculate the Analysis\n",
    "minimum = df['overall'].min()\n",
    "Q1 = df['overall'].quantile(0.25)\n",
    "median = df['overall'].median()\n",
    "Q3 = df['overall'].quantile(0.75)\n",
    "maximum = df['overall'].max()\n",
    "\n",
    "#Create a dictionary for the DFs\n",
    "\n",
    "analysis_of_performance = {\n",
    "    'Minimum': minimum,\n",
    "    'Q1 (25th Percentile)': Q1,\n",
    "    'Median (50th Percentile)': median,\n",
    "    'Q3 (75th Percentile)': Q3,\n",
    "    'Maximum': maximum\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "analysis_of_performance_df = pd.DataFrame(analysis_of_performance, index=[0])\n",
    "\n",
    "# Display the DataFrame\n",
    "display(analysis_of_performance_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c2a88-940e-469a-8dc1-750977db7c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.boxplot(df['overall'])  \n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Box Plot of Overall Ratings')\n",
    "plt.xlabel('Overall Rating')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e2ec0-0c14-41e0-a116-8d25a26d9d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Desired order of player positions\n",
    "work_order = ['Low/Low', 'Low/Medium', 'Low/High', 'Medium/Low', 'Medium/Medium', 'Medium/High', 'High/Low', 'High/Medium', 'High/High']\n",
    "\n",
    "# Calculate the average overall rating for each player position\n",
    "avg_overall_by_work_rate = df.groupby('work_rate')['overall'].mean().reset_index()\n",
    "\n",
    "# Convert player_position to a categorical type with the specified order\n",
    "avg_overall_by_work_rate['work_rate'] = pd.Categorical(avg_overall_by_work_rate['work_rate'], categories=work_order, ordered=True)\n",
    "\n",
    "# Sort the DataFrame by the ordered work_rate\n",
    "avg_overall_by_work_rate = avg_overall_by_work_rate.sort_values('work_rate')\n",
    "\n",
    "# Create the bar graph\n",
    "plt.bar(avg_overall_by_work_rate['work_rate'], avg_overall_by_work_rate['overall'])\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Average Overall Rating by Work Rate')\n",
    "plt.xlabel('Work Rate')\n",
    "plt.ylabel('Average Overall Rating')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83f2cc6-833a-45da-8d2d-6fdc5959e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure there are no NaN values in the 'work_rate' and 'overall' columns\n",
    "work_rate_clean_df = df.dropna(subset=['work_rate', 'overall'])\n",
    "\n",
    "# Group the data by work_rate\n",
    "work_rate_groups = [work_rate_clean_df[work_rate_clean_df['work_rate'] == rate]['overall'] for rate in work_rate_clean_df['work_rate'].unique()]\n",
    "\n",
    "# Create side-by-side box plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(work_rate_groups, labels=work_rate_clean_df['work_rate'].unique())\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Overall Performance by Work Rate')\n",
    "plt.xlabel('Work Rate')\n",
    "plt.ylabel('Overall Performance')\n",
    "\n",
    "# Rotate the x-ticks for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4962f02-4053-4e0d-af33-40a939690c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing ANOVA\n",
    "anova_result = st.f_oneway(\n",
    "    df[df['work_rate'] == 'Low/Low']['overall'],\n",
    "    df[df['work_rate'] == 'Low/Medium']['overall'],\n",
    "    df[df['work_rate'] == 'Low/High']['overall'],\n",
    "    df[df['work_rate'] == 'Medium/Low']['overall'],\n",
    "    df[df['work_rate'] == 'Medium/Medium']['overall'],\n",
    "    df[df['work_rate'] == 'Medium/High']['overall'],\n",
    "    df[df['work_rate'] == 'High/Low']['overall'],\n",
    "    df[df['work_rate'] == 'High/Medium']['overall'],\n",
    "    df[df['work_rate'] == 'High/High']['overall']\n",
    ")\n",
    "\n",
    "print('ANOVA result:', anova_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe896ad2-8754-4f26-abcc-87ccc797017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Perform Tukey's HSD test\n",
    "tukey = pairwise_tukeyhsd(endog=df['overall'],    \n",
    "                          groups=df['work_rate'],  \n",
    "                          alpha=0.05)            \n",
    "\n",
    "# Display the test results\n",
    "print(tukey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6952fa-5049-4ffc-8f5c-1620da7ef1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'contract length' as the difference between 'contract_valid_until' and 'joined_year'\n",
    "contract_df = df[['overall', 'joined_year', 'contract_valid_until']].copy()\n",
    "contract_df['contract length'] = (contract_df['contract_valid_until'] - contract_df['joined_year'] + 1)\n",
    "contract_df_clean = contract_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337e0157-2b03-4dd4-ab1c-2231502f1c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the Analysis\n",
    "minimum_2 = contract_df_clean['contract length'].min()\n",
    "Q1_2 = contract_df_clean['contract length'].quantile(0.25)\n",
    "median_2 = contract_df_clean['contract length'].median()\n",
    "Q3_2 = contract_df_clean['contract length'].quantile(0.75)\n",
    "maximum_2 = contract_df_clean['contract length'].max()\n",
    "\n",
    "#Create a dictionary for the DFs\n",
    "\n",
    "analysis_of_contract = {\n",
    "    'Minimum': minimum_2,\n",
    "    'Q1 (25th Percentile)': Q1_2,\n",
    "    'Median (50th Percentile)': median_2,\n",
    "    'Q3 (75th Percentile)': Q3_2,\n",
    "    'Maximum': maximum_2\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "analysis_of_contract_df = pd.DataFrame(analysis_of_contract, index=[0])\n",
    "\n",
    "# Display the DataFrame\n",
    "display(analysis_of_contract_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b4912-79ed-491d-b78a-d99c2f9c4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(contract_df_clean['contract length'])  \n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Box Plot of Contract Length')\n",
    "plt.xlabel('Contract Length')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a96bed7-8613-48f4-832c-7142c818f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure there are no NaN values in the cleaned DataFrame\n",
    "contract_clean_df = contract_df_clean.dropna(subset=['contract length', 'overall'])\n",
    "\n",
    "# Define the variables for regression\n",
    "contract_length = contract_clean_df['contract length']  \n",
    "overall_performance = contract_clean_df['overall']\n",
    "\n",
    "# Perform linear regression\n",
    "slope, intercept, r_value, p_value, std_err = st.linregress(contract_length, overall_performance)\n",
    "\n",
    "# Create regression line values\n",
    "regress_values = slope * contract_length + intercept\n",
    "\n",
    "# Create equation line for annotation\n",
    "line_eq = f\"y = {round(slope, 2)}x + {round(intercept, 2)}\"\n",
    "\n",
    "# Create correlation coefficient string\n",
    "correlation_eq = f\"R = {round(r_value, 2)}\"\n",
    "\n",
    "# Step 6: Graph\n",
    "plt.scatter(contract_length, overall_performance, label='Data Points')\n",
    "plt.plot(contract_length, regress_values, 'r-', label='Regression Line')\n",
    "plt.title('Contract Length vs. Overall Performance')\n",
    "plt.xlabel('Contract Length')\n",
    "plt.ylabel('Overall Performance')\n",
    "plt.legend()\n",
    "\n",
    "# Annotate the equation and correlation on the graph\n",
    "plt.annotate(line_eq, (0.05, 0.85), fontsize=12, color='red', xycoords='axes fraction')\n",
    "plt.annotate(correlation_eq, (0.05, 0.80), fontsize=12, color='blue', xycoords='axes fraction')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print R-squared value\n",
    "print(f\"R²: {r_value**2}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
